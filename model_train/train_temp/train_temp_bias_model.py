import argparse
import os.path
import sys
from pathlib import Path

# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
FILE = Path(__file__).resolve()
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‡è®¾è„šæœ¬åœ¨é¡¹ç›®å­ç›®å½•ä¸­ï¼‰
ROOT = FILE.parents[0]  # é¡¹ç›®æ ¹ç›®å½•
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
# è®¾ç½®å·¥ä½œç›®å½•ä¸ºé¡¹ç›®æ ¹ç›®å½•
os.chdir(ROOT)


import time

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from datasets import   FaceData
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))
from models.temp_biase.temp_bias import  CrossAttentionRegressionModel
import sys
# print(sys.path)
# è®­ç»ƒå‡½æ•°
# æ›´é«˜çº§çš„ç‰ˆæœ¬ï¼ŒåŒ…å«æ›´å¤šæŒ‡æ ‡å’Œå¯è§†åŒ–
def train_model(model, train_loader, val_loader, num_epochs=500, lr=1e-3, early_stopping_patience=20):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    model.to(device)
    criterion = nn.MSELoss()
    # criterion = nn.L1Loss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)

    history = {
        'train_loss': [], 'val_loss': [], 'learning_rate': [],
        'train_mae': [], 'val_mae': [], 'epoch_times': []
    }

    best_val_loss = float('inf')
    best_model_weights = None
    patience_counter = 0
    # åœ¨è®­ç»ƒå¼€å§‹å‰åˆå§‹åŒ–GradScaler
    scaler = torch.amp.GradScaler("cuda")
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        # åœ¨è®­ç»ƒå¼€å§‹å‰åˆå§‹åŒ–GradScaler
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_mae = 0.0
        train_mae_max = 0.
        train_pbar = tqdm(train_loader, desc=f'ğŸƒ è®­ç»ƒ Epoch {epoch + 1}/{num_epochs}',
                          bar_format='{l_bar}{bar:25}{r_bar}{bar:-10b}')

        for batch_idx, (images, extra_features, labels) in enumerate(train_pbar):
            images, extra_features, labels = images.to(device), extra_features.to(device), labels.to(device)
            optimizer.zero_grad()
            # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
            with torch.amp.autocast('cuda'):
                outputs = model(images, extra_features)
                loss = criterion(outputs, labels)
                mae = torch.mean(torch.abs(outputs - labels))
                train_mae_max = max(train_mae_max, torch.abs(outputs - labels).max())

            # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­
            scaler.scale(loss).backward()
            # ä½¿ç”¨scalerè¿›è¡Œæ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            # ä½¿ç”¨scaleræ›´æ–°å‚æ•°
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item()
            train_mae += mae.item()

            # å®æ—¶æ›´æ–°è¿›åº¦æ¡
            if batch_idx % 10 == 0:
                train_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'MAE': f'{mae.item():.4f}',
                    'AvgLoss': f'{train_loss / (batch_idx + 1):.4f}'
                })

        avg_train_loss = train_loss / len(train_loader)
        avg_train_mae = train_mae / len(train_loader)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_mae = 0.0
        val_mae_max = 0.
        val_pbar = tqdm(val_loader, desc=f'âœ… éªŒè¯ Epoch {epoch + 1}/{num_epochs}',
                        bar_format='{l_bar}{bar:25}{r_bar}{bar:-10b}')

        with torch.no_grad():
            for batch_idx, (images, extra_features, labels) in enumerate(val_pbar):
                images, extra_features, labels = images.to(device), extra_features.to(device), labels.to(device)
                outputs = model(images, extra_features)
                loss = criterion(outputs, labels)
                ae = torch.abs(outputs - labels)
                mae = torch.mean(ae)
                val_mae_max = max(val_mae_max, ae.max())
                val_loss += loss.item()
                val_mae += mae.item()

                val_pbar.set_postfix({
                    'ValLoss': f'{loss.item():.4f}',
                    'ValMAE': f'{mae.item():.4f}',
                    'AvgValLoss': f'{val_loss / (batch_idx + 1):.4f}'
                })

        avg_val_loss = val_loss / len(val_loader)
        avg_val_mae = val_mae / len(val_loader)
        epoch_time = time.time() - epoch_start_time

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']

        # è®°å½•å†å²
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        history['train_mae'].append(avg_train_mae)
        history['val_mae'].append(avg_val_mae)
        history['learning_rate'].append(current_lr)
        history['epoch_times'].append(epoch_time)

        # æ—©åœæ£€æŸ¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_weights = model.state_dict().copy()
            torch.save(model.state_dict(), 'best_model.pth')
            patience_counter = 0
            improvement_msg = "âœ¨ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜!"
        else:
            patience_counter += 1
            improvement_msg = f"â³ æ—©åœè®¡æ•°: {patience_counter}/{early_stopping_patience}"

            if patience_counter >= early_stopping_patience:
                print(f"\nğŸš¨ æ—©åœè§¦å‘ï¼åœ¨ Epoch {epoch + 1} åœæ­¢è®­ç»ƒ")
                break

        # æ‰“å°è¯¦ç»†çš„epochæ€»ç»“
        print(f"\n{'=' * 70}")
        print(f"ğŸ“Š Epoch {epoch + 1}/{num_epochs} æ€»ç»“:")
        print(f"  è®­ç»ƒæŸå¤±: {avg_train_loss:.6f} | éªŒè¯æŸå¤±: {avg_val_loss:.6f}")
        print(f"  è®­ç»ƒMAE:  {avg_train_mae:.6f} | éªŒè¯MAE:  {avg_val_mae:.6f}")
        print(f"  è®­ç»ƒMAE_MAX:  {train_mae_max:.6f} | éªŒè¯MAE_MAX:  {val_mae_max:.6f}")
        print(f"  å­¦ä¹ ç‡: {current_lr:.3g} | æ—¶é—´: {epoch_time:.2f}ç§’")
        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        print(f"  {improvement_msg}")
        print(f"{'=' * 70}\n")

    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_weights is not None:
        model.load_state_dict(best_model_weights)
        print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼åŠ è½½æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.6f}")
    return model, history


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    ç”¨æ³•ç¤ºä¾‹ï¼š
    python train.py --image_dirs img1 img2 --true_list 36.8 36.8 --batch_size 128 --epochs 500
    """
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ¸©åº¦åå·®æ ¡å‡†æ¨¡å‹')

    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--image_dirs', nargs='+',
                        help='å›¾ç‰‡ç›®å½•åˆ—è¡¨ï¼Œç”¨ç©ºæ ¼åˆ†éš”å¤šä¸ªç›®å½•')
    parser.add_argument('--true_list', nargs='+', type=float,
                        help='çœŸå®æ¸©åº¦å€¼åˆ—è¡¨ï¼Œç”¨ç©ºæ ¼åˆ†éš”å¤šä¸ªå€¼')
    parser.add_argument('--train_ratio', type=float, default=0.8,
                        help='è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8')

    parser.add_argument('--model_dims', type=int, default=128,
                        help='æ¨¡å‹éšè—å±‚ç»´åº¦')

    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--batch_size', type=int, default=128,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--epochs', type=int, default=500,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-3,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--patience', type=int, default=10,
                        help='æ—©åœè€å¿ƒå€¼')

    return parser.parse_args()

# ä¸»å‡½æ•°
def main():
    # æ•°æ®è·¯å¾„
    # åˆ›å»ºæ•°æ®é›†
    args = parse_args()
    image_dir = args.image_dirs
    true_list = args.true_list
    batch_size = args.batch_size
    number_of_workers = args.num_workers
    model_dims = args.model_dims
    num_epochs = args.epochs
    lr = args.lr


    dataset = FaceData(image_dir,true_list)
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=number_of_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True)

    # åˆ›å»ºæ¨¡å‹
    model = CrossAttentionRegressionModel(hidden_dim=model_dims)
    # model = TransformerTemp(vector_in=8, vector_len=64, vector_dim=128, vector_layer=4, img_layer=4, decoder_layer=2)
    model.cuda()
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_dataset)}")

    # # è®­ç»ƒæ¨¡å‹
    train_model(model, train_loader, val_loader, num_epochs=num_epochs, lr=lr,early_stopping_patience=10)
    print("æ¨¡å‹å·²ä¿å­˜ä¸º 'temperature_regressor.pth'")

    # æµ‹è¯•é¢„æµ‹
    model.load_state_dict(torch.load("best_model.pth", weights_only=True))
    model.eval()
    mse_list = []
    mae_list = []

    import pandas as pd
    with torch.no_grad():
        # å–ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œæµ‹è¯•
        test_images, test_extra, test_labels = next(iter(val_loader))
        test_images, test_extra = test_images.to('cuda' if torch.cuda.is_available() else 'cpu'), test_extra.to(
            'cuda' if torch.cuda.is_available() else 'cpu')
        predictions = model(test_images, test_extra).cpu()
        # è®°å½•ä¸‹æ¥é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„ mse å’Œ mae æˆ‘å¸Œæœ›èƒ½åœ¨å¾ªç¯ç»“æŸå å®ä¾‹åŒ–å­˜å‚¨ï¼Œå¹¶ä¸”å¯è§†åŒ–
        mse_list.extend((predictions - test_labels).pow(2).tolist())
        mae_list.extend((abs(predictions - test_labels)).tolist())
    results = pd.DataFrame({'MSE': mse_list, 'MAE': mae_list})
    results.to_csv('results.csv', index=False)



if __name__ == "__main__":
    main()
